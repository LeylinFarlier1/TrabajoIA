# Trabajo IA Server v0.1.9 Performance & Infrastructure Roadmap

## Objetivos principales
- Reducir la latencia p95 de las herramientas FRED por debajo de 400 ms en cachés calientes.
- Disminuir la varianza de tiempos de respuesta en >50 % mediante pooling/async y coordinación de reintentos.
- Exponer telemetría operativa (logs estructurados + métricas) para medir el impacto de las optimizaciones.
- Asegurar resiliencia ante límites de FRED con estrategias compartidas de rate limiting/backoff.

## Iniciativas clave

### 1. Cacheo inteligente de respuestas FRED
- **Acción:** introducir capa de caché con backend conmutable (Redis en despliegues multiinstancia, `diskcache` embebido para modo local/testing).
- **Ámbito:** `src/trabajo_ia_server/tools/fred/*.py` utilizando utilidades compartidas en un nuevo módulo `utils/cache.py`.
- **Estrategia de expiración:** TTL diferenciados (5 min para búsquedas, 1 h para metadatos, 15 min para respuestas de series).
- **Telemetría:** contadores de hits/misses e invalidaciones voluntarias.
- **Dependencias previas:** métricas básicas disponibles (ver iniciativa 3) para validar mejoras.
- **Estado (v0.1.9-alpha):** capa in-memory activa con configuración desde `Config`, métricas de hits/misses y cliente compartido `utils/fred_client.py` que centraliza el cacheo para todas las herramientas FRED.
- **Estado (v0.1.9-beta):** soporte multi-backend (memoria, DiskCache, Redis) con rutas configurables, invalidación por namespace y control de TTL por herramienta desde variables de entorno.

### 2. Cliente HTTP asíncrono y pooling compartido
- **Acción:** migrar a `httpx.AsyncClient` gestionado como singleton en `server.py` y expuesto vía inyección en herramientas.
- **Consideraciones:**
  - Confirmar soporte async en FastMCP; si no está disponible, encapsular `AsyncClient` detrás de `anyio.to_thread.run_sync` temporalmente.
  - Definir User-Agent consistente derivado de `Config.SERVER_VERSION` y cabeceras comunes.
  - Refactorizar herramientas multi-llamada (p.ej. agregados de categorías) para ejecutar peticiones concurrentes con `asyncio.gather`.
- **Metas de rendimiento:** reducir latencia de búsquedas compuestas 2-5× bajo carga.
- **Riesgos:** incremento de complejidad y necesidad de pruebas de carrera; mitigar con tests async y revisión de compatibilidad MCP.

### 3. Observabilidad y telemetría operativa
- **Acción:**
  - Extender `utils/logger.py` con formato JSON y soporte para IDs de correlación.
  - Crear `utils/metrics.py` con cliente Prometheus (`prometheus_client`) y exponer `/metrics` o handler MCP equivalente.
  - Añadir health-check CLI/método que valide conectividad FRED + estado de caché.
- **Métricas propuestas:** latencia por herramienta, tasas de error, nº de reintentos, aciertos/fallos de caché, códigos 429.
- **Salida:** dashboards configurables y alertas básicas sobre latencia > umbral.

### 4. Gobernanza de rate limits y reintentos
- **Acción:** diseñar planificador central de backoff que coordine reintentos, evitando esperas bloqueantes en cada herramienta.
- **Implementación:**
  - Compartir estado (p.ej. `asyncio.Lock` + contador de tokens) para coordinar la ventana de FRED.
  - Configuración en `config.py` para límites por minuto/segundo y habilitar “circuit breaker” ante fallos sostenidos.
  - Registrar telemetría de códigos 429 y tiempos de espera (ver iniciativa 3).
- **Resultado esperado:** reducción de fallos en ráfaga y control operativo sobre presupuesto de peticiones.
- **Estado (v0.1.9-beta):** limitador compartido con ventanas por segundo/minuto y penalizaciones coordinadas tras 429, integrado en el cliente FRED para evitar picos concurrentes.

## Plan de entregas

| Fase | Duración | Alcance |
| --- | --- | --- |
| **v0.1.9-alpha (Sprint 1)** | 2 semanas | Observabilidad (iniciativa 3) + cimientos de caché (interfaces, métricas). |
| **v0.1.9-beta (Sprint 2)** | 2 semanas | Cacheo completo (iniciativa 1) + rate limiting coordinado (iniciativa 4) ✅ |
| **v0.2.0 (Sprints 3-4)** | 3-4 semanas | Cliente async y pooling (iniciativa 2) + ajustes basados en métricas recolectadas. |

## Riesgos y mitigaciones

| Riesgo | Prob. | Impacto | Mitigación |
| --- | --- | --- | --- |
| Falta de soporte async en FastMCP | Media | Alto | Implementar capa de compatibilidad sync y planificar migración completa para v0.2.0. |
| Caché entrega datos obsoletos | Baja | Alto | TTL conservadores, opción de invalidación manual y monitoreo de versiones FRED. |
| Rate limiter sobre-restringe | Media | Medio | Parámetros configurables + métricas para ajustar en tiempo real. |
| Complejidad adicional genera regresiones | Alta | Medio | Tests automatizados, feature flags y despliegues progresivos. |

## Próximos pasos inmediatos
1. Confirmar capacidades async de FastMCP y documentar limitaciones.
2. Seleccionar dependencias de caché/metrics compatibles con la política de despliegue.
3. Redactar RFC breve para la capa de caché y coordinar revisiones con el equipo.
4. Preparar tableros iniciales de observabilidad para validar métricas en staging.
